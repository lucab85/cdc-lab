# M2V1 – Debezium Connector Deep-Dive

> **Pre-requisite:** Make sure the stack is running:
> ```bash
> docker compose up -d
> ```

---

## Step 1 – Review the Debezium connector configuration

1. **View the connector JSON file:**

```bash
cat connectors/postgres-cdc-connector.json | jq .
```

2. **Key sections to point out:**

| Setting | Purpose |
|---------|---------|
| `connector.class` | The Debezium PostgreSQL connector |
| `database.hostname` | Postgres container name |
| `topic.prefix` | Prefix for all Kafka topics (`appdb`) |
| `table.include.list` | Which tables to capture |
| `snapshot.mode` | How to handle initial data |

Say:
> "This JSON file defines everything about our CDC connector: what database to connect to, which tables to capture, and how to format the messages."

---

## Step 2 – Understand snapshot modes

1. **Check the current snapshot mode:**

```bash
cat connectors/postgres-cdc-connector.json | jq '.config["snapshot.mode"]'
```

2. **Snapshot mode options:**

| Mode | Behavior | Use Case |
|------|----------|----------|
| `initial` | Snapshot existing data, then tail WAL | Production, local dev |
| `initial_only` | Snapshot only, no streaming | CI pipelines, testing |
| `never` | Skip snapshot, only new changes | Resume after failure |
| `when_needed` | Snapshot if slot is missing | Recovery scenarios |

Say:
> "For local development, `initial` gives us fast feedback. For CI pipelines, `initial_only` ensures deterministic runs."

---

## Step 3 – Check the replication slot

1. **Connect to Postgres and view replication slots:**

```bash
docker compose exec postgres psql -U appuser -d appdb
```

```sql
SELECT slot_name, plugin, active FROM pg_replication_slots;
```

You should see `debezium_slot` with `pgoutput` plugin.

2. **Exit psql:**

```sql
\q
```

Say:
> "Debezium uses a PostgreSQL replication slot to track its position in the WAL. This ensures no changes are lost even if the connector restarts."

---

## Step 4 – Register the connector via REST API

1. **Check if the connector is already registered:**

```bash
curl -s http://localhost:8083/connectors | jq .
```

2. **If not registered, create it:**

```bash
curl -X POST -H "Content-Type: application/json" \
  --data @connectors/postgres-cdc-connector.json \
  http://localhost:8083/connectors | jq .
```

3. **Check connector status:**

```bash
curl -s http://localhost:8083/connectors/postgres-cdc-connector/status | jq .
```

Look for `"state": "RUNNING"` in both connector and task.

Say:
> "Kafka Connect exposes a REST API for managing connectors. You can create, update, pause, resume, and delete connectors without restarting anything."

---

## Step 5 – Inspect the created Kafka topics

1. **List all topics created by Debezium:**

```bash
docker compose exec kafka kafka-topics \
  --bootstrap-server kafka:9092 \
  --list | grep appdb
```

You should see:
- `appdb.public.customers`
- `appdb.public.orders`

2. **Describe a topic to see partitions and config:**

```bash
docker compose exec kafka kafka-topics \
  --bootstrap-server kafka:9092 \
  --describe \
  --topic appdb.public.customers
```

Say:
> "Debezium creates topics following the pattern `<prefix>.<schema>.<table>`. Each table gets its own topic."

---

## Step 6 – Inspect message key and value structure

1. **Insert a test row:**

```bash
docker compose exec postgres psql -U appuser -d appdb -c "
INSERT INTO customers (customer_id, first_name, last_name, email, country)
VALUES (99, 'Test', 'User', 'test@example.com', 'US')
ON CONFLICT (customer_id) DO UPDATE SET email = EXCLUDED.email;
"
```

2. **Consume with key printed:**

```bash
docker compose exec kafka kafka-console-consumer \
  --bootstrap-server kafka:9092 \
  --topic appdb.public.customers \
  --from-beginning \
  --max-messages 20
```

3. **Pretty-print the value:**

```bash
docker compose exec kafka kafka-console-consumer \
  --bootstrap-server kafka:9092 \
  --topic appdb.public.customers \
  --from-beginning \
  --max-messages 1 | jq .
```

Point out:
- **Key:** `{"customer_id": 99}` — the primary key
- **Value:** Debezium envelope with `before`, `after`, `op`, `source`

Say:
> "The key is always the primary key of the table. This enables Kafka log compaction and downstream upsert semantics."

---

## Step 7 – Check Schema Registry subjects

1. **List all registered subjects:**

```bash
curl -s http://localhost:8081/subjects | jq .
```

> This returns `[]` because we're using JSON converters. With Avro converters, you'd see subjects like `appdb.public.customers-key` and `appdb.public.customers-value`.

2. **Check Schema Registry config:**

```bash
curl -s http://localhost:8081/config | jq .
```

Say:
> "Schema Registry stores Avro/Protobuf schemas when using those converters. With JSON, schemas are embedded in each message instead."

---

## Step 8 – Explore the Kafka Connect REST API

1. **List available connector plugins:**

```bash
curl -s http://localhost:8083/connector-plugins | jq '.[].class' | grep -i debezium
```

2. **Get connector configuration:**

```bash
curl -s http://localhost:8083/connectors/postgres-cdc-connector/config | jq .
```

3. **Pause and resume the connector:**

```bash
# Pause
curl -X PUT http://localhost:8083/connectors/postgres-cdc-connector/pause

# Check status (should show PAUSED)
curl -s http://localhost:8083/connectors/postgres-cdc-connector/status | jq '.connector.state'

# Resume
curl -X PUT http://localhost:8083/connectors/postgres-cdc-connector/resume

# Check status (should show RUNNING)
curl -s http://localhost:8083/connectors/postgres-cdc-connector/status | jq '.connector.state'
```

Say:
> "The REST API lets you manage connectors dynamically. This is useful for maintenance windows or debugging."

---

## Step 9 – View connector in Kafka UI

1. **Open Kafka UI in browser:**

```
http://localhost:8085
```

2. **Navigate to:**
   - **Topics** → See `appdb.public.customers` and `appdb.public.orders`
   - **Kafka Connect** → See `postgres-cdc-connector` status
   - **Messages** → Browse actual CDC messages

Say:
> "Kafka UI provides a visual way to explore topics, messages, and connector status without using the CLI."

---

## Key Configuration Reference

| Setting | Value | Purpose |
|---------|-------|---------|
| `snapshot.mode` | `initial` | Snapshot then stream |
| `slot.name` | `debezium_slot` | Replication slot name |
| `table.include.list` | `public.customers,public.orders` | Tables to capture |
| `topic.prefix` | `appdb` | Kafka topic prefix |
| `key.converter` | `JsonConverter` | Message key format |
| `value.converter` | `JsonConverter` | Message value format |

---

## Practical Tips

**For local development:**
- Use `snapshot.mode=initial` for fast feedback
- Keep `table.include.list` tight to avoid noisy topics
- Use Kafka UI to quickly browse messages

**For CI pipelines:**
- Use `snapshot.mode=initial_only` for deterministic runs
- Use unique `slot.name` per environment
- Clean up slots after tests to avoid WAL bloat

---

## Quick Reset

To reset and replay the demo:

```bash
docker compose down -v
docker compose up -d
# Wait ~30s for services to start, then re-register Debezium connector:
curl -X POST -H "Content-Type: application/json" \
  --data @connectors/postgres-cdc-connector.json \
  http://localhost:8083/connectors
```

To delete and recreate the connector:

```bash
# Delete
curl -X DELETE http://localhost:8083/connectors/postgres-cdc-connector

# Recreate
curl -X POST -H "Content-Type: application/json" \
  --data @connectors/postgres-cdc-connector.json \
  http://localhost:8083/connectors
```
