# M2V3 – CI Checks, DLQ, and Observability

> **Pre-requisite:** Make sure the stack is running:
> ```bash
> docker compose up -d
> ```

---

## Step 1 – Review the CI schema validation script

1. **View the validation script:**

```bash
cat ci/validate_schemas.py
```

2. **Key validation checks:**

| Check | Purpose |
|-------|---------|
| Valid JSON/Avro syntax | Catches typos and malformed schemas |
| Required fields have types | Ensures schema is complete |
| New fields have defaults | Enforces backward compatibility |

Say:
> "This script runs in CI before any schema can be merged. It catches obvious problems early, before they hit Schema Registry."

---

## Step 2 – Run schema validation locally

1. **Run the validation script:**

```bash
python3 ci/validate_schemas.py schemas/
```

2. **Expected output for valid schemas:**

```
Validating schemas/customer-v1.avsc... OK
Validating schemas/customer-v2-fixed.avsc... OK
All schemas valid!
```

3. **Test with a breaking schema:**

```bash
python3 ci/validate_schemas.py schemas/customer-v2-breaking.avsc
```

Say:
> "Running validation locally gives fast feedback. In CI, this would block a PR with incompatible schemas."

---

## Step 3 – Review the GitHub Actions workflow

1. **View the CI workflow:**

```bash
cat ci/README.md
```

2. **Key CI pipeline stages:**

```yaml
jobs:
  schema-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Install schema tools
        run: pip install fastavro
      - name: Validate Avro schemas
        run: python scripts/validate_schemas.py schemas/
```

3. **Make this job required** for merges to `main` in your GitHub/GitLab settings.

Say:
> "This CI job runs on every PR. If schemas are invalid or incompatible, the merge is blocked automatically."

---

## Step 4 – Review DLQ configuration in the connector

1. **View the connector's error handling settings:**

```bash
cat connectors/postgres-cdc-connector.json | jq '.config | {errors_tolerance: .["errors.tolerance"], errors_log: .["errors.log.enable"]}'
```

2. **Key DLQ settings to add:**

```json
{
  "errors.tolerance": "all",
  "errors.deadletterqueue.topic.name": "dlq.customers",
  "errors.deadletterqueue.context.headers.enable": "true",
  "errors.log.enable": "true",
  "errors.log.include.messages": "true"
}
```

| Setting | Purpose |
|---------|---------|
| `errors.tolerance` | `all` = continue on errors, `none` = fail fast |
| `errors.deadletterqueue.topic.name` | Where bad messages go |
| `errors.deadletterqueue.context.headers.enable` | Include error details in headers |

Say:
> "With DLQ configured, bad messages don't crash the pipeline—they're routed to a separate topic for investigation."

---

## Step 5 – Check connector status and metrics

1. **Get connector status:**

```bash
curl -s http://localhost:8083/connectors/postgres-cdc-connector/status | jq .
```

2. **Check task status:**

```bash
curl -s http://localhost:8083/connectors/postgres-cdc-connector/tasks/0/status | jq .
```

3. **Look for these indicators:**

| Field | Healthy Value |
|-------|---------------|
| `connector.state` | `RUNNING` |
| `tasks[0].state` | `RUNNING` |
| `tasks[0].trace` | (empty = no errors) |

Say:
> "The Connect REST API exposes health status. In production, poll this endpoint and alert when state != RUNNING."

---

## Step 6 – Check consumer group lag

1. **List all consumer groups:**

```bash
docker compose exec kafka kafka-consumer-groups \
  --bootstrap-server kafka:9092 \
  --list
```

2. **Describe a specific consumer group:**

```bash
docker compose exec kafka kafka-consumer-groups \
  --bootstrap-server kafka:9092 \
  --group connect-postgres-cdc-connector \
  --describe
```

3. **Key columns to monitor:**

| Column | Meaning |
|--------|---------|
| `CURRENT-OFFSET` | Last committed offset |
| `LOG-END-OFFSET` | Latest message in partition |
| `LAG` | Messages behind (should be low) |

Say:
> "Consumer lag tells you if your pipeline is keeping up. High lag means you're falling behind and may need to scale."

---

## Step 7 – Check for DLQ messages

1. **List topics to find DLQ:**

```bash
docker compose exec kafka kafka-topics \
  --bootstrap-server kafka:9092 \
  --list | grep -i dlq
```

2. **If DLQ topic exists, check for messages:**

```bash
docker compose exec kafka kafka-console-consumer \
  --bootstrap-server kafka:9092 \
  --topic dlq.customers \
  --from-beginning \
  --max-messages 5 \
  --property print.headers=true
```

3. **No messages = good!** If messages exist, inspect the error headers.

Say:
> "An empty DLQ is healthy. If messages appear here, investigate the error headers to find the root cause."

---

## Step 8 – View metrics in Kafka UI

1. **Open Kafka UI in browser:**

```
http://localhost:9080
```

2. **Navigate to key sections:**

| Section | What to Check |
|---------|---------------|
| **Topics** | Message counts, partition distribution |
| **Consumer Groups** | Lag per group |
| **Kafka Connect** | Connector health status |

3. **Set up alerts for:**
   - Consumer lag > 10,000 for 5+ minutes
   - Connector state != RUNNING
   - DLQ message count increasing

Say:
> "Kafka UI gives you a visual dashboard. For production, export these metrics to Prometheus/Grafana and set up alerts."

---

## Step 9 – Create an incident runbook

1. **Key sections for your runbook:**

**Symptoms:**
```
□ Schema Registry 409 errors in logs
□ Consumer lag > threshold (e.g., 10,000 messages)
□ DLQ rate > 0.1% of traffic
□ Connector status = FAILED
```

**Quick Triage Commands:**

```bash
# Check Schema Registry for recent changes
curl -s http://localhost:8081/subjects | jq .

# Check connector status
curl -s http://localhost:8083/connectors/postgres-cdc-connector/status | jq .

# Check consumer lag
docker compose exec kafka kafka-consumer-groups \
  --bootstrap-server kafka:9092 \
  --group connect-postgres-cdc-connector \
  --describe

# Check DLQ for errors
docker compose exec kafka kafka-console-consumer \
  --bootstrap-server kafka:9092 \
  --topic dlq.customers \
  --from-beginning \
  --max-messages 5
```

**Standard Actions:**

| Issue | Action |
|-------|--------|
| Schema incompatibility | Freeze changes, decide rollback vs roll-forward |
| High consumer lag | Check for errors, scale consumers if healthy |
| High DLQ rate | Identify bad data pattern, fix source |
| Connector FAILED | Check logs, restart connector |

Say:
> "A runbook turns tribal knowledge into repeatable steps. When an alert fires at 3 AM, nobody should be guessing."

---

## Key Metrics to Monitor

| Metric | Warning Threshold | Critical Threshold |
|--------|-------------------|-------------------|
| Consumer lag | > 10,000 for 5 min | > 100,000 for 15 min |
| DLQ message rate | > 0.1% of traffic | > 1% of traffic |
| Schema Registry 409s | > 5 in 10 min | > 20 in 10 min |
| Connector restarts | > 2 in 1 hour | > 5 in 1 hour |

---

## Error Budget Example

Define what "healthy" means:

```
Pipeline: customers_canonical
- Acceptable DLQ rate: < 0.1% per day
- Acceptable lag: < 5 minutes behind real-time
- Acceptable downtime: < 5 minutes per week
```

When budget is exceeded → trigger incident review.

---

## Quick Reset

To reset and replay the demo:

```bash
docker compose down -v
docker compose up -d
# Wait ~30s for services to start, then re-register Debezium connector:
curl -X POST -H "Content-Type: application/json" \
  --data @connectors/postgres-cdc-connector.json \
  http://localhost:8083/connectors
```

To restart just the connector:

```bash
# Restart connector
curl -X POST http://localhost:8083/connectors/postgres-cdc-connector/restart

# Restart specific task
curl -X POST http://localhost:8083/connectors/postgres-cdc-connector/tasks/0/restart
```
